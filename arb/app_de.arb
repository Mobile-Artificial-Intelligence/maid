{
    "@@locale": "de",
    "friendlyName": "Deutsch",
    "localeTitle": "Sprache",
    "defaultLocale": "Standardsprache",
    "loading": "Laden...",
    "loadModel": "Modell laden",
    "downloadModel": "Modell herunterladen",
    "noModelSelected": "Kein Modell ausgewählt",
    "noModelLoaded": "Kein Modell geladen",
    "localModels": "Lokale Modelle",
    "size": "Größe",
    "parameters": "Parameter",
    "delete": "Löschen",
    "select": "Auswählen",
    "import": "Importieren",
    "export": "Exportieren",
    "edit": "Bearbeiten",
    "regenerate": "Neu generieren",
    "chatsTitle": "Chats",
    "newChat": "Neuer Chat",
    "anErrorOccurred": "Ein Fehler ist aufgetreten",
    "errorTitle": "Fehler",
    "key": "Schlüssel",
    "value": "Wert",
    "ok": "OK",
    "done": "Fertig",
    "close": "Schließen",
    "save": "Speichern",
    "saveLabel": "Speichern {label}",
    "selectTag": "Tag auswählen",
    "next": "Weiter",
    "previous": "Zurück",
    "contentShared": "Inhalt geteilt",
    "setUserImage": "Benutzerbild festlegen",
    "setAssistantImage": "Assistentenbild festlegen",
    "loadUserImage": "Benutzerbild laden",
    "loadAssistantImage": "Assistentenbild laden",
    "userName": "Benutzername",
    "assistantName": "Assistentenname",
    "user": "Benutzer",
    "assistant": "Assistent",
    "cancel": "Abbrechen",
    "aiEcosystem": "KI-Ökosystem",
    "llamaCpp": "Llama CPP",
    "llamaCppModel": "Llama CPP Modell",
    "remoteModel": "Remote-Modell",
    "refreshRemoteModels": "Remote-Modelle aktualisieren",
    "ollama": "Ollama",
    "searchLocalNetwork": "Lokales Netzwerk durchsuchen",
    "localNetworkSearchTitle": "Suche im lokalen Netzwerk",
    "localNetworkSearchContent": "Diese Funktion benötigt zusätzliche Berechtigungen, um Ihr lokales Netzwerk nach Ollama-Instanzen zu durchsuchen.",
    "openAI": "OpenAI",
    "mistral": "Mistral",
    "anthropic": "Anthropic",
    "gemini": "Gemini",
    "modelParameters": "Modellparameter",
    "addParameter": "Parameter hinzufügen",
    "removeParameter": "Parameter entfernen",
    "saveParameters": "Parameter speichern",
    "importParameters": "Parameter importieren",
    "exportParameters": "Parameter exportieren",
    "selectAiEcosystem": "KI-Ökosystem auswählen",
    "selectRemoteModel": "Remote-Modell auswählen",
    "selectThemeMode": "App-Designmodus auswählen",
    "themeMode": "Designmodus",
    "themeModeSystem": "System",
    "themeModeLight": "Hell",
    "themeModeDark": "Dunkel",
    "themeSeedColor": "Design-Farbton",
    "editMessage": "Nachricht bearbeiten",
    "settingsTitle": "Einstellungen",
    "aiSettings": "{aiControllerType} Einstellungen",
    "userSettings": "Benutzereinstellungen",
    "assistantSettings": "Assistenteneinstellungen",
    "systemSettings": "Systemeinstellungen",
    "systemPrompt": "System-Prompt",
    "clearChats": "Chats löschen",
    "resetSettings": "Einstellungen zurücksetzen",
    "clearCache": "Cache leeren",
    "aboutTitle": "Über",
    "aboutContent": "Maid ist eine plattformübergreifende, kostenlose und Open-Source-Anwendung zur Nutzung von llama.cpp-Modellen lokal und für die Fernverwendung mit Ollama-, Mistral- und OpenAI-Modellen. Maid unterstützt SillyTavern-Charakterkarten, sodass Sie mit Ihren Lieblingscharakteren interagieren können. Maid ermöglicht den direkten Download einer kuratierten Liste von Modellen aus Hugging Face. Maid wird unter der MIT-Lizenz vertrieben und ohne jegliche Gewährleistung bereitgestellt, weder ausdrücklich noch impliziert. Maid ist nicht mit Hugging Face, Meta (Facebook), MistralAI, OpenAI, Google, Microsoft oder anderen Unternehmen verbunden, die mit dieser Anwendung kompatible Modelle anbieten.",
    "leadMaintainer": "Hauptbetreuer",
    "apiKey": "API-Schlüssel",
    "baseUrl": "Basis-URL",
    "clearPrompt": "Prompt löschen",
    "submitPrompt": "Prompt senden",
    "stopPrompt": "Prompt stoppen",
    "typeMessage": "Nachricht eingeben...",
    "code": "Code",
    "copyLabel": "{label} kopieren",
    "labelCopied": "{label} in die Zwischenablage kopiert!"
}
